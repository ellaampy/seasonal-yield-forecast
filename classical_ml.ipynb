{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7509041-193b-450b-8b7b-a87f3cffa424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, glob\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "import optuna\n",
    "from data_preparation.dataset import YieldDataset\n",
    "import torch\n",
    "import pickle as pkl\n",
    "from models.utils import evalMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d0da2f-fafb-477f-ad0c-eb56e6cb4eed",
   "metadata": {},
   "source": [
    "## prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71e554c2-a62a-471f-af82-131c61751042",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = {\n",
    "    'results_path': '/app/dev/Seasonal_Climate/results',\n",
    "    'predictor_path': '/app/dev/Seasonal_Climate/onedrive/cy_bench_16daybins_wheat_US_v4.csv',\n",
    "    'yield_path': '/app/dev/Seasonal_Climate/cybench/cybench-data/wheat/US/yield_wheat_US.csv',\n",
    "    'feature_selector': [\"tavg\",\"prec\",'tmax','tmin',\"fpar\",\"ndvi\",\"ssm\",\"rsm\",\"cwb\",\"et0\",\"rad\",\n",
    "                         \"awc\",\"bulk_density\",'drainage_class_3', 'drainage_class_4', \n",
    "                         'drainage_class_5','drainage_class_6','lat', 'lon', 'yield_-1', \n",
    "                         'yield_-2', 'yield_-3'],  \n",
    "    'temporal_truncation': [3, 24],  \n",
    "    'proportion': 100,\n",
    "    'state_selector': ['US-08', 'US-20', 'US-31', 'US-40', 'US-46', 'US-48'],  # ['BR41' 'BR42' 'BR43'] \n",
    "    'train_years': list(range(2004, 2018)),\n",
    "    'val_years': [2018, 2019, 2020],\n",
    "    'test_years': [2021, 2022, 2023],\n",
    "    'display_step': 20,\n",
    "    'input_dim': 19,\n",
    "    'num_workers': -1,\n",
    "    'seed': [3407],\n",
    "    'optimizer_switch': 'ADAM',\n",
    "    'num_trials':20\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9386ee66-7bd9-4d9a-a97e-8d1dc18edf85",
   "metadata": {},
   "source": [
    "## random forest block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83f5a51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_train(config, exp_name='rf'):\n",
    "    \n",
    "    # prepare output_dir \n",
    "    exp_params = {}\n",
    "    \n",
    "    # make directory for experiment\n",
    "    output_dir = os.path.join(config['results_path'], exp_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # -- collector for metrics\n",
    "    metrics_train = []\n",
    "    metrics_val = []\n",
    "    metrics_test = []   \n",
    "\n",
    "    for s in config['seed']:\n",
    "        np.random.seed(s)\n",
    "        random.seed(s)\n",
    "        torch.manual_seed(s)\n",
    "\n",
    "        # Initialize YieldDataset with various parameters\n",
    "        train_dataset = YieldDataset(\n",
    "            predictor_path= config['predictor_path'],\n",
    "            yield_path= config['yield_path'],\n",
    "            norm = None,\n",
    "            years= config['train_years'],\n",
    "            feature_selector= config['feature_selector'],\n",
    "            temporal_truncation= config['temporal_truncation'],\n",
    "            proportion= config['proportion'],\n",
    "            state_selector= config['state_selector']\n",
    "        )\n",
    "\n",
    "        val_dataset = YieldDataset(\n",
    "            predictor_path= config['predictor_path'],\n",
    "            yield_path= config['yield_path'],\n",
    "            norm = train_dataset.norm_values,\n",
    "            years= config['val_years'],\n",
    "            feature_selector= config['feature_selector'],\n",
    "            temporal_truncation= config['temporal_truncation'],\n",
    "            proportion= config['proportion'],\n",
    "            state_selector= config['state_selector']\n",
    "        )\n",
    "\n",
    "        test_dataset = YieldDataset(\n",
    "            predictor_path= config['predictor_path'],\n",
    "            yield_path= config['yield_path'],\n",
    "            norm = train_dataset.norm_values,\n",
    "            years= config['test_years'],\n",
    "            feature_selector= config['feature_selector'],\n",
    "            temporal_truncation= config['temporal_truncation'],\n",
    "            proportion= config['proportion'],\n",
    "            state_selector= config['state_selector']\n",
    "        )\n",
    "\n",
    "        # ----- create array for experiment settings\n",
    "        X_t, y_t  = train_dataset.truncated_data.reshape(train_dataset.truncated_data.shape[0], -1), train_dataset.target\n",
    "        X_v, y_v = val_dataset.truncated_data.reshape(val_dataset.truncated_data.shape[0], -1), val_dataset.target\n",
    "        X_d, y_d = test_dataset.truncated_data.reshape(test_dataset.truncated_data.shape[0], -1), test_dataset.target\n",
    "\n",
    "\n",
    "        # tune only once\n",
    "        if s == config['seed'][0]:\n",
    "\n",
    "            def objective(trial):\n",
    "\n",
    "                params = {\n",
    "                    'n_estimators' : trial.suggest_int('n_estimators', 100, 500),\n",
    "                    'max_depth' : trial.suggest_int('max_depth', 3, 10),\n",
    "                    # 'max_features' : trial.suggest_categorical('max_features', ['auto', 'sqrt']), \n",
    "                    'min_samples_split' : trial.suggest_int('min_samples_split', 5, 15),\n",
    "                    'bootstrap' : trial.suggest_categorical('bootstrap', [True, False]),\n",
    "                    'n_jobs' : trial.suggest_categorical('n_jobs', [-1]), \n",
    "                    'random_state' : trial.suggest_categorical('random_state', [s])\n",
    "                }\n",
    "\n",
    "                clf = RandomForestRegressor(**params)\n",
    "                clf.fit(X_t, y_t)\n",
    "\n",
    "                # intermediate_value = clf.score(X_v, y_v)\n",
    "                y_p = clf.predict(X_v)\n",
    "                intermediate_value =  mean_squared_error(y_v, y_p)\n",
    "\n",
    "                if trial.should_prune():\n",
    "                    raise optuna.TrialPruned()\n",
    "\n",
    "                return intermediate_value\n",
    "            \n",
    "            # optimize study\n",
    "            study = optuna.create_study(direction=\"minimize\")\n",
    "            study.optimize(objective, n_trials=config['num_trials']) \n",
    "            print(study.best_params)\n",
    "            \n",
    "            # save study\n",
    "            study_df = study.trials_dataframe(attrs=('number', 'value', 'params', 'state'))\n",
    "            study_df.to_csv(os.path.join(output_dir, 'study_params_'+'{}.csv'.format(exp_name)))\n",
    "            \n",
    "\n",
    "            # dump best parameters\n",
    "            exp_params[exp_name] = study.best_params\n",
    "\n",
    "\n",
    "## ============================== ACTIVATE BLOCK TO SAVE METRICS FOR TRAIN, VALIDATION AND TEST\n",
    "\n",
    "        # use best params from tuning\n",
    "        rf_opt = RandomForestRegressor(**study.best_params)\n",
    "        rf_opt.fit(X_t, y_t)\n",
    "\n",
    "        # predict training year\n",
    "        y_pred_t = rf_opt.predict(X_t)\n",
    "\n",
    "        # predict validation year\n",
    "        y_pred_v = rf_opt.predict(X_v)\n",
    "\n",
    "    #     #predict test year\n",
    "    #     y_pred_d = rf_opt.predict(X_d)\n",
    "    #     pkl.dump(y_d, open(os.path.join(output_dir, 'y_true_test_data.pkl'), 'wb'))\n",
    "    #     pkl.dump(y_pred_d, open(os.path.join(output_dir, 'y_pred_test_data.pkl'), 'wb'))\n",
    "\n",
    "\n",
    "        # print('training metrics')\n",
    "        mape, mse, nrmse, r2, r = evalMetrics(y_t, y_pred_t)\n",
    "        metrics_train.append([exp_name, 'train', str(s), mape, mse, nrmse, r2, r])\n",
    "        # print('MAPE= {} , MSE = {} , NRMSE = {} , r2 ={} , R = {}'.format(mape, mse, nrmse, r2, r))\n",
    "\n",
    "        # print('validation metrics')\n",
    "        mape, mse, nrmse, r2, r = evalMetrics(y_v, y_pred_v)\n",
    "        metrics_val.append([exp_name, 'validation', str(s), mape, mse, nrmse, r2, r])\n",
    "        # print('MAPE= {} , MSE = {} ,NRMSE = {} , r2 ={} , R = {}'.format(mape, mse, nrmse, r2, r))\n",
    "\n",
    "\n",
    "        # # # print('test metrics d')\n",
    "        # mape, mse, nrmse, r2, r = evalMetrics(y_d, y_pred_d)\n",
    "        # # print('MAPE= {} , MSE = {} , NRMSE = {} , r2 ={} , R = {}'.format(mape, mse, nrmse, r2, r))\n",
    "        # metrics_test.append([ exp_name,'test', str(s), mape, mse, nrmse, r2, r])\n",
    "\n",
    "\n",
    "    \n",
    "    results_df_train = pd.DataFrame(metrics_train, columns=['exp_name', 'mode','seed', 'MAPE', 'MSE', 'NRMSE', 'R2', 'r'])\n",
    "    results_df_val = pd.DataFrame(metrics_val, columns=['exp_name', 'mode', 'seed', 'MAPE', 'MSE', 'NRMSE', 'R2', 'r'])\n",
    "    df_combined = pd.concat([results_df_train, results_df_val], ignore_index=True)\n",
    "\n",
    "    # results_df_test = pd.DataFrame(metrics_test, columns=['exp_name', 'mode','seed', 'MAPE', 'MSE','NRMSE', 'R2', 'r'])\n",
    "    # df_combined = pd.concat([results_df_train, results_df_val, results_df_test], ignore_index=True)\n",
    "    \n",
    "    df_combined.to_csv(os.path.join(output_dir, '{}.csv'.format(exp_name)))\n",
    "\n",
    "    # save exp parameters\n",
    "    with open(os.path.join(output_dir, 'params.json'), 'w') as file:\n",
    "        file.write(json.dumps(exp_params, indent=4))\n",
    "\n",
    "    # # save test ids\n",
    "    # pkl.dump(test_dataset.ids , open(os.path.join(output_dir, 'test_geoid.pkl'), 'wb'))\n",
    "\n",
    "    # # save test years\n",
    "    # pkl.dump(test_dataset.years , open(os.path.join(output_dir, 'test_years.pkl'), 'wb'))\n",
    "        \n",
    "    print(exp_name, 'done')\n",
    "\n",
    "    #=========================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72b91ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-08-28 06:48:29,541]\u001b[0m A new study created in memory with name: no-name-e2079779-09b2-4f87-b085-6684c4823751\u001b[0m\n",
      "\u001b[32m[I 2024-08-28 06:48:32,552]\u001b[0m Trial 0 finished with value: 0.5282861434470537 and parameters: {'n_estimators': 352, 'max_depth': 4, 'min_samples_split': 9, 'bootstrap': True, 'n_jobs': -1, 'random_state': 3407}. Best is trial 0 with value: 0.5282861434470537.\u001b[0m\n",
      "\u001b[32m[I 2024-08-28 06:48:34,587]\u001b[0m Trial 1 finished with value: 0.47895293462532124 and parameters: {'n_estimators': 130, 'max_depth': 8, 'min_samples_split': 5, 'bootstrap': True, 'n_jobs': -1, 'random_state': 3407}. Best is trial 1 with value: 0.47895293462532124.\u001b[0m\n",
      "\u001b[32m[I 2024-08-28 06:48:35,581]\u001b[0m Trial 2 finished with value: 0.5651813609869315 and parameters: {'n_estimators': 129, 'max_depth': 3, 'min_samples_split': 7, 'bootstrap': True, 'n_jobs': -1, 'random_state': 3407}. Best is trial 1 with value: 0.47895293462532124.\u001b[0m\n",
      "\u001b[32m[I 2024-08-28 06:48:38,398]\u001b[0m Trial 3 finished with value: 0.4803763514814186 and parameters: {'n_estimators': 238, 'max_depth': 6, 'min_samples_split': 10, 'bootstrap': True, 'n_jobs': -1, 'random_state': 3407}. Best is trial 1 with value: 0.47895293462532124.\u001b[0m\n",
      "\u001b[32m[I 2024-08-28 06:48:44,162]\u001b[0m Trial 4 finished with value: 0.4758290298126376 and parameters: {'n_estimators': 399, 'max_depth': 8, 'min_samples_split': 8, 'bootstrap': True, 'n_jobs': -1, 'random_state': 3407}. Best is trial 4 with value: 0.4758290298126376.\u001b[0m\n",
      "\u001b[32m[I 2024-08-28 06:48:53,038]\u001b[0m Trial 5 finished with value: 0.6329671473198514 and parameters: {'n_estimators': 485, 'max_depth': 6, 'min_samples_split': 8, 'bootstrap': False, 'n_jobs': -1, 'random_state': 3407}. Best is trial 4 with value: 0.4758290298126376.\u001b[0m\n",
      "\u001b[32m[I 2024-08-28 06:49:01,262]\u001b[0m Trial 6 finished with value: 0.6295981575987436 and parameters: {'n_estimators': 454, 'max_depth': 6, 'min_samples_split': 11, 'bootstrap': False, 'n_jobs': -1, 'random_state': 3407}. Best is trial 4 with value: 0.4758290298126376.\u001b[0m\n",
      "\u001b[32m[I 2024-08-28 06:49:05,540]\u001b[0m Trial 7 finished with value: 0.6048537437609525 and parameters: {'n_estimators': 278, 'max_depth': 5, 'min_samples_split': 11, 'bootstrap': False, 'n_jobs': -1, 'random_state': 3407}. Best is trial 4 with value: 0.4758290298126376.\u001b[0m\n",
      "\u001b[32m[I 2024-08-28 06:49:10,705]\u001b[0m Trial 8 finished with value: 0.4828465336687491 and parameters: {'n_estimators': 451, 'max_depth': 6, 'min_samples_split': 14, 'bootstrap': True, 'n_jobs': -1, 'random_state': 3407}. Best is trial 4 with value: 0.4758290298126376.\u001b[0m\n",
      "\u001b[32m[I 2024-08-28 06:49:16,192]\u001b[0m Trial 9 finished with value: 0.7713193812967262 and parameters: {'n_estimators': 257, 'max_depth': 7, 'min_samples_split': 9, 'bootstrap': False, 'n_jobs': -1, 'random_state': 3407}. Best is trial 4 with value: 0.4758290298126376.\u001b[0m\n",
      "\u001b[32m[I 2024-08-28 06:49:22,256]\u001b[0m Trial 10 finished with value: 0.48347528812467105 and parameters: {'n_estimators': 367, 'max_depth': 10, 'min_samples_split': 15, 'bootstrap': True, 'n_jobs': -1, 'random_state': 3407}. Best is trial 4 with value: 0.4758290298126376.\u001b[0m\n",
      "\u001b[32m[I 2024-08-28 06:49:24,569]\u001b[0m Trial 11 finished with value: 0.4830291281120114 and parameters: {'n_estimators': 113, 'max_depth': 9, 'min_samples_split': 5, 'bootstrap': True, 'n_jobs': -1, 'random_state': 3407}. Best is trial 4 with value: 0.4758290298126376.\u001b[0m\n",
      "\u001b[32m[I 2024-08-28 06:49:27,324]\u001b[0m Trial 12 finished with value: 0.47331398473556846 and parameters: {'n_estimators': 183, 'max_depth': 8, 'min_samples_split': 5, 'bootstrap': True, 'n_jobs': -1, 'random_state': 3407}. Best is trial 12 with value: 0.47331398473556846.\u001b[0m\n",
      "\u001b[32m[I 2024-08-28 06:49:30,525]\u001b[0m Trial 13 finished with value: 0.4740031980319757 and parameters: {'n_estimators': 199, 'max_depth': 8, 'min_samples_split': 6, 'bootstrap': True, 'n_jobs': -1, 'random_state': 3407}. Best is trial 12 with value: 0.47331398473556846.\u001b[0m\n",
      "\u001b[32m[I 2024-08-28 06:49:33,784]\u001b[0m Trial 14 finished with value: 0.4788894584300763 and parameters: {'n_estimators': 189, 'max_depth': 10, 'min_samples_split': 6, 'bootstrap': True, 'n_jobs': -1, 'random_state': 3407}. Best is trial 12 with value: 0.47331398473556846.\u001b[0m\n",
      "\u001b[32m[I 2024-08-28 06:49:36,701]\u001b[0m Trial 15 finished with value: 0.4724500263655348 and parameters: {'n_estimators': 191, 'max_depth': 8, 'min_samples_split': 6, 'bootstrap': True, 'n_jobs': -1, 'random_state': 3407}. Best is trial 15 with value: 0.4724500263655348.\u001b[0m\n",
      "\u001b[32m[I 2024-08-28 06:49:39,761]\u001b[0m Trial 16 finished with value: 0.47919185341798565 and parameters: {'n_estimators': 179, 'max_depth': 9, 'min_samples_split': 5, 'bootstrap': True, 'n_jobs': -1, 'random_state': 3407}. Best is trial 15 with value: 0.4724500263655348.\u001b[0m\n",
      "\u001b[32m[I 2024-08-28 06:49:47,113]\u001b[0m Trial 17 finished with value: 0.47269712620244814 and parameters: {'n_estimators': 327, 'max_depth': 7, 'min_samples_split': 7, 'bootstrap': True, 'n_jobs': -1, 'random_state': 3407}. Best is trial 15 with value: 0.4724500263655348.\u001b[0m\n",
      "\u001b[32m[I 2024-08-28 06:49:54,956]\u001b[0m Trial 18 finished with value: 0.7716157410931401 and parameters: {'n_estimators': 297, 'max_depth': 7, 'min_samples_split': 7, 'bootstrap': False, 'n_jobs': -1, 'random_state': 3407}. Best is trial 15 with value: 0.4724500263655348.\u001b[0m\n",
      "\u001b[32m[I 2024-08-28 06:49:59,051]\u001b[0m Trial 19 finished with value: 0.5023428381201208 and parameters: {'n_estimators': 325, 'max_depth': 5, 'min_samples_split': 13, 'bootstrap': True, 'n_jobs': -1, 'random_state': 3407}. Best is trial 15 with value: 0.4724500263655348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 191, 'max_depth': 8, 'min_samples_split': 6, 'bootstrap': True, 'n_jobs': -1, 'random_state': 3407}\n",
      "rf_v4 done\n"
     ]
    }
   ],
   "source": [
    "rf_train(config, exp_name='rf_v4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
