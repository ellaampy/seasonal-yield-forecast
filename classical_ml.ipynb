{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7509041-193b-450b-8b7b-a87f3cffa424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, glob\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "import optuna\n",
    "from data_preparation.dataset import YieldDataset\n",
    "import torch\n",
    "import pickle as pkl\n",
    "from models.utils import evalMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d0da2f-fafb-477f-ad0c-eb56e6cb4eed",
   "metadata": {},
   "source": [
    "## prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71e554c2-a62a-471f-af82-131c61751042",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = {\n",
    "    'results_path': '/app/dev/Seasonal_Climate/results',\n",
    "    'predictor_path': '/app/dev/Seasonal_Climate/onedrive/cy_bench_8daybins_wheat_US.csv',\n",
    "    'yield_path': '/app/dev/Seasonal_Climate/cybench/cybench-data/wheat/US/yield_wheat_US.csv',\n",
    "    'feature_selector': None,  \n",
    "    'max_timesteps': 46,\n",
    "    'temporal_truncation': None,  \n",
    "    'proportion': 100,\n",
    "    'state_selector': ['US-08', 'US-20', 'US-31', 'US-40', 'US-46', 'US-48'],  # ['BR41' 'BR42' 'BR43'] \n",
    "    'aez_selector': None,\n",
    "    'train_years': list(range(2004, 2018)),\n",
    "    'val_years': [2018, 2019, 2020],\n",
    "    'test_years': [2021, 2022],\n",
    "    'display_step': 20,\n",
    "    'input_dim': 19,\n",
    "    'num_workers': 4,\n",
    "    'seed': [3407],\n",
    "    'optimizer_switch': 'ADAM',\n",
    "    'epochs':100,\n",
    "    'num_trials':1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9386ee66-7bd9-4d9a-a97e-8d1dc18edf85",
   "metadata": {},
   "source": [
    "## random forest block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83f5a51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_train(config, exp_name='rf'):\n",
    "    \n",
    "    # prepare output_dir \n",
    "    exp_params = {}\n",
    "    \n",
    "    # make directory for experiment\n",
    "    output_dir = os.path.join(config['results_path'], exp_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # -- collector for metrics\n",
    "    metrics_train = []\n",
    "    metrics_val = []\n",
    "    metrics_test = []   \n",
    "\n",
    "    for s in config['seed']:\n",
    "        np.random.seed(s)\n",
    "        random.seed(s)\n",
    "        torch.manual_seed(s)\n",
    "\n",
    "        # Initialize YieldDataset with various parameters\n",
    "        train_dataset = YieldDataset(\n",
    "            predictor_path= config['predictor_path'],\n",
    "            yield_path= config['yield_path'],\n",
    "            norm = None,\n",
    "            years= config['train_years'],\n",
    "            feature_selector= config['feature_selector'],\n",
    "            max_timesteps= config['max_timesteps'],\n",
    "            temporal_truncation= config['temporal_truncation'],\n",
    "            proportion= config['proportion'],\n",
    "            state_selector= config['state_selector'],\n",
    "            aez_selector= config['aez_selector']\n",
    "        )\n",
    "\n",
    "        val_dataset = YieldDataset(\n",
    "            predictor_path= config['predictor_path'],\n",
    "            yield_path= config['yield_path'],\n",
    "            norm = train_dataset.norm_values,\n",
    "            years= config['val_years'],\n",
    "            feature_selector= config['feature_selector'],\n",
    "            max_timesteps= config['max_timesteps'],\n",
    "            temporal_truncation= config['temporal_truncation'],\n",
    "            proportion= config['proportion'],\n",
    "            state_selector= config['state_selector'],\n",
    "            aez_selector= config['aez_selector']\n",
    "        )\n",
    "\n",
    "        test_dataset = YieldDataset(\n",
    "            predictor_path= config['predictor_path'],\n",
    "            yield_path= config['yield_path'],\n",
    "            norm = train_dataset.norm_values,\n",
    "            years= config['test_years'],\n",
    "            feature_selector= config['feature_selector'],\n",
    "            max_timesteps= config['max_timesteps'],\n",
    "            temporal_truncation= config['temporal_truncation'],\n",
    "            proportion= config['proportion'],\n",
    "            state_selector= config['state_selector'],\n",
    "            aez_selector= config['aez_selector']\n",
    "        )\n",
    "\n",
    "        # ----- create array for experiment settings\n",
    "        X_t, y_t  = train_dataset.truncated_data.reshape(train_dataset.truncated_data.shape[0], -1), train_dataset.target\n",
    "        X_v, y_v = val_dataset.truncated_data.reshape(val_dataset.truncated_data.shape[0], -1), val_dataset.target\n",
    "        X_d, y_d = test_dataset.truncated_data.reshape(test_dataset.truncated_data.shape[0], -1), test_dataset.target\n",
    "\n",
    "\n",
    "        # tune only once\n",
    "        if s == config['seed'][0]:\n",
    "\n",
    "            def objective(trial):\n",
    "\n",
    "                params = {\n",
    "                    'n_estimators' : trial.suggest_int('n_estimators', 100, 500),\n",
    "                    'max_depth' : trial.suggest_int('max_depth', 3, 10),\n",
    "                    # 'max_features' : trial.suggest_categorical('max_features', ['auto', 'sqrt']), \n",
    "                    'min_samples_split' : trial.suggest_int('min_samples_split', 5, 15),\n",
    "                    'bootstrap' : trial.suggest_categorical('bootstrap', [True, False]),\n",
    "                    'n_jobs' : trial.suggest_categorical('n_jobs', [-1]), \n",
    "                    'random_state' : trial.suggest_categorical('random_state', [s])\n",
    "                }\n",
    "\n",
    "                clf = RandomForestRegressor(**params)\n",
    "                clf.fit(X_t, y_t)\n",
    "\n",
    "                # intermediate_value = clf.score(X_v, y_v)\n",
    "                y_p = clf.predict(X_v)\n",
    "                intermediate_value =  mean_squared_error(y_v, y_p)\n",
    "\n",
    "                if trial.should_prune():\n",
    "                    raise optuna.TrialPruned()\n",
    "\n",
    "                return intermediate_value\n",
    "            \n",
    "            # optimize study\n",
    "            study = optuna.create_study(direction=\"minimize\")\n",
    "            study.optimize(objective, n_trials=config['num_trials']) \n",
    "            print(study.best_params)\n",
    "            \n",
    "            # save study\n",
    "            study_df = study.trials_dataframe(attrs=('number', 'value', 'params', 'state'))\n",
    "            study_df.to_csv(os.path.join(output_dir, 'study_params_'+'{}.csv'.format(exp_name)))\n",
    "            \n",
    "\n",
    "            # dump best parameters\n",
    "            exp_params[exp_name] = study.best_params\n",
    "\n",
    "\n",
    "## ============================== ACTIVATE BLOCK TO SAVE METRICS FOR TRAIN, VALIDATION AND TEST\n",
    "\n",
    "    #     # use best params from tuning\n",
    "    #     rf_opt = RandomForestRegressor(**study.best_params)\n",
    "    #     rf_opt.fit(X_t, y_t)\n",
    "\n",
    "    #     # predict training year\n",
    "    #     y_pred_t = rf_opt.predict(X_t)\n",
    "\n",
    "    #     # predict validation year\n",
    "    #     y_pred_v = rf_opt.predict(X_v)\n",
    "\n",
    "    #     #predict test year\n",
    "    #     y_pred_d = rf_opt.predict(X_d)\n",
    "    #     pkl.dump(y_d, open(os.path.join(output_dir, 'y_true_test_data.pkl'), 'wb'))\n",
    "    #     pkl.dump(y_pred_d, open(os.path.join(output_dir, 'y_pred_test_data.pkl'), 'wb'))\n",
    "\n",
    "\n",
    "    #     # print('training metrics')\n",
    "    #     mape, rmse, nrmse, r2, r = evalMetrics(y_t, y_pred_t)\n",
    "    #     metrics_train.append([exp_name, 'train', str(s), mape, rmse, nrmse, r2, r])\n",
    "    #     # print('MAPE= {} , RMSE = {} , NRMSE = {} , r2 ={} , R = {}'.format(mape, rmse, nrmse, r2, r))\n",
    "\n",
    "    #     # print('validation metrics')\n",
    "    #     mape, rmse, nrmse, r2, r = evalMetrics(y_v, y_pred_v)\n",
    "    #     metrics_val.append([exp_name, 'validation', str(s), mape, rmse, nrmse, r2, r])\n",
    "    #     # print('MAPE= {} , RMSE = {} ,NRMSE = {} , r2 ={} , R = {}'.format(mape, rmse, nrmse, r2, r))\n",
    "\n",
    "\n",
    "    #     # # print('test metrics d')\n",
    "    #     mape, rmse, nrmse, r2, r = evalMetrics(y_d, y_pred_d)\n",
    "    #     # print('MAPE= {} , RMSE = {} , NRMSE = {} , r2 ={} , R = {}'.format(mape, rmse, nrmse, r2, r))\n",
    "    #     metrics_test.append([ exp_name,'test', str(s), mape, rmse, nrmse, r2, r])\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # results_df_train = pd.DataFrame(metrics_train, columns=['exp_name', 'mode','seed', 'MAPE', 'RMSE', 'NRMSE', 'R2', 'r'])\n",
    "    # results_df_val = pd.DataFrame(metrics_val, columns=['exp_name', 'mode', 'seed', 'MAPE', 'RMSE', 'NRMSE', 'R2', 'r'])\n",
    "    # results_df_test = pd.DataFrame(metrics_test, columns=['exp_name', 'mode','seed', 'MAPE', 'RMSE','NRMSE', 'R2', 'r'])\n",
    "    # df_combined = pd.concat([results_df_train, results_df_val, results_df_test], ignore_index=True)\n",
    "    # df_combined.to_csv(os.path.join(output_dir, '{}.csv'.format(exp_name)))\n",
    "\n",
    "    # # save exp parameters\n",
    "    # with open(os.path.join(output_dir, 'params.json'), 'w') as file:\n",
    "    #     file.write(json.dumps(exp_params, indent=4))\n",
    "\n",
    "    # # save test ids\n",
    "    # pkl.dump(test_dataset.ids , open(os.path.join(output_dir, 'test_geoid.pkl'), 'wb'))\n",
    "\n",
    "    # # save test years\n",
    "    # pkl.dump(test_dataset.years , open(os.path.join(output_dir, 'test_years.pkl'), 'wb'))\n",
    "        \n",
    "    # print(exp_name, 'done')\n",
    "\n",
    "    #=========================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72b91ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-08-26 06:22:38,867]\u001b[0m A new study created in memory with name: no-name-d8fea0d2-51ac-4fd0-8aa5-b306451a0db6\u001b[0m\n",
      "\u001b[32m[I 2024-08-26 06:23:02,458]\u001b[0m Trial 0 finished with value: 0.727690694519767 and parameters: {'n_estimators': 428, 'max_depth': 8, 'min_samples_split': 13, 'bootstrap': False, 'n_jobs': -1, 'random_state': 3407}. Best is trial 0 with value: 0.727690694519767.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 428, 'max_depth': 8, 'min_samples_split': 13, 'bootstrap': False, 'n_jobs': -1, 'random_state': 3407}\n",
      "rf done\n"
     ]
    }
   ],
   "source": [
    "rf_train(config, exp_name='rf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
