{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from modules import preprocess\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "state_selector = ['08', '20', '31', '40', '46', '48'] \n",
    "static_features = [\"awc\", \"bulk_density\", \"drainage_class_1\", \"drainage_class_2\", \"drainage_class_3\", \"drainage_class_4\", \"drainage_class_5\", \"drainage_class_6\"]\n",
    "temporal_prefixes = [\"tavg\", \"prec\", \"tmin\", \"tmax\", \"ndvi\", \"fpar\", \"rad\", \"et0\", \"cwb\", \"ssm\", \"rsm\"]\n",
    "# Enable autoreload for Jupyter notebooks\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Define study crop and country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/shapefiles/US/tl_2023_us_county.shp wheat US (1, 365) (8, 7) 19 [2021, 2022, 2023]\n"
     ]
    }
   ],
   "source": [
    "# USER INPUTS\n",
    "country = \"US\" # one of [\"US\", \"BR\"]\n",
    "crop = \"wheat\" # one of [\"maize\", \"wheat\"]\n",
    "\n",
    "shapefile_path, crop_season_in_days_of_year, crop_season_in_months, offset, test_years = preprocess.get_study_metadata(country, crop)\n",
    "crop_season_in_days_of_year = tuple([1, 365])\n",
    "crop_season_in_months = tuple([8, 7])\n",
    "print(shapefile_path, crop, country, crop_season_in_days_of_year, crop_season_in_months, offset, test_years)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Read data\n",
    "\n",
    "From CY-Bench, we have five predictor datasets. \n",
    " \n",
    "| **ID** | **Name**        | **Time** | **Variables**                         | **Steps**                                    | \n",
    "|--------|-----------------|----------|---------------------------------------|----------------------------------------------|\n",
    "| 1      | FPAR            | bins     | fpar                                  | filter adm_ids, filter crop season           |            \n",
    "| 2      | METEO           | daily    | tmin, tmax, prec, rad, tavg, et0, cwb | filter adm_ids, filter crop season,<br>resample to 8-day bins  |        \n",
    "| 3      | NDVI            | bins     | ndvi                                  | filter adm_ids, filter crop season, pivotieren           |           \n",
    "| 4      | SOIL MOISTURE   | daily    | ssm, rsm                              | filter adm_ids, filter crop season, <br>resample to 8-day bins, pivotieren  |          \n",
    "| 5      | SOIL            | static   | awc, bulk_density, drainage_class     | filter adm_ids, pivotieren                                |         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CY-Bench data\n",
    "fpar = pd.read_csv(\"../data/CY-Bench/{}/{}/fpar_{}_{}.csv\".format(country, crop, crop, country)) \n",
    "meteo = pd.read_csv(\"../data/CY-Bench/{}/{}/meteo_{}_{}.csv\".format(country, crop, crop, country), usecols=['crop_name','adm_id','date','rad','et0','cwb', 'tavg', 'tmin', 'tmax', 'prec'])\n",
    "ndvi = pd.read_csv(\"../data/CY-Bench/{}/{}/ndvi_{}_{}.csv\".format(country, crop, crop, country)) \n",
    "soil_moisture = pd.read_csv(\"../data/CY-Bench/{}/{}/soil_moisture_{}_{}.csv\".format(country, crop,  crop, country))\n",
    "soil = pd.read_csv(\"../data/CY-Bench/{}/{}/soil_{}_{}.csv\".format(country, crop, crop, country)) \n",
    "yield_data = pd.read_csv(\"../data/CY-Bench/{}/{}/yield_{}_{}.csv\".format(country, crop, crop, country))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cy_bench_data = [fpar, soil_moisture, ndvi, soil, meteo]\n",
    "relevant_adm_ids = yield_data[\"adm_id\"].unique()\n",
    "cy_bench_data = preprocess.filter_predictors_by_adm_ids(cy_bench_data, relevant_adm_ids)\n",
    "fpar, soil_moisture, ndvi, soil, meteo = cy_bench_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_cy_bench_data = [fpar, soil_moisture, ndvi, meteo]\n",
    "temporal_cy_bench_data = preprocess.preprocess_temporal_data(temporal_cy_bench_data, crop_season_in_months, crop_season_in_days_of_year, crop, country)\n",
    " \n",
    "fpar, soil_moisture, ndvi, meteo = temporal_cy_bench_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge\n",
    "predictors = (soil_moisture\n",
    "              .merge(ndvi \n",
    "                     .merge(meteo\n",
    "                            .merge(fpar, on=[\"adm_id\", \"harvest_year\"], how=\"inner\"), \n",
    "                            on=[\"adm_id\", \"harvest_year\"], how=\"inner\"), \n",
    "                     on=[\"adm_id\", \"harvest_year\"], how=\"inner\")\n",
    "              .merge(soil.drop(\"crop_name\", axis=1), on=\"adm_id\", how=\"left\"))\n",
    "\n",
    "# one-hot encode drainage_class and drop\n",
    "predictors = (predictors\n",
    "              .join(pd.get_dummies(predictors[\"drainage_class\"].astype('Int64'), dtype=int, prefix=\"drainage_class\"))\n",
    "              .drop(\"drainage_class\", axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = preprocess.interpolate_fpar_timesteps(predictors, \"tavg\")\n",
    "predictors = preprocess.order_temporal_features(predictors, temporal_prefixes)\n",
    "predictors = predictors.assign(state=predictors[\"adm_id\"].apply(lambda x: x.split(\"-\")[1]))\n",
    "predictors = predictors.loc[predictors[\"state\"].isin(['08', '20', '31', '40', '46', '48'])].reset_index(drop=True)\n",
    "predictors = predictors.drop(\"state\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_16day_bins = preprocess.temporal_aggregation_from8day_to_window(predictors, temporal_prefixes, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have two predictor datasets:\n",
    "\n",
    "- predictors: where the temporal features are in 8day bins\n",
    "- predictors_16day_bins: where the temporal features are in 16day bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add additional features\n",
    "\n",
    "### lat, lon of adm_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_shape = gpd.read_file(shapefile_path)\n",
    "\n",
    "us_shape = us_shape.assign(adm_id=\"US-\"+us_shape[\"STATEFP\"]+\"-\"+us_shape[\"COUNTYFP\"],\n",
    "                centroid=us_shape[\"geometry\"].to_crs(epsg=32723).centroid)[[\"adm_id\", \"geometry\", \"centroid\"]]\n",
    "\n",
    "county_centroids = us_shape.assign(lon=us_shape[\"centroid\"].to_crs(epsg=4326).x, lat=us_shape[\"centroid\"].to_crs(epsg=4326).y).drop([\"centroid\", \"geometry\"], axis=1)\n",
    "\n",
    "predictors = predictors.merge(county_centroids, on=\"adm_id\", how=\"left\")\n",
    "predictors_16day_bins = predictors_16day_bins.merge(county_centroids, on=\"adm_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### yield of past years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "yield_data = yield_data.loc[(yield_data[\"adm_id\"].isin(predictors[\"adm_id\"].unique())) & (yield_data[\"harvest_year\"].between(1999, 2023))].reset_index(drop=True)\n",
    "\n",
    "yield_data_pivot = yield_data.pivot(index=\"adm_id\", columns=\"harvest_year\", values=\"yield\")\n",
    "yield_data_pivot = (pd.DataFrame(index=pd.MultiIndex.from_frame(yield_data[[\"adm_id\", \"harvest_year\"]]))\n",
    "                  .reset_index(level=1).rename(columns={\"level_1\": \"harvest_year\"})\n",
    "                  .merge(yield_data_pivot, left_index=True, right_index=True, how=\"left\")\n",
    "                  .reset_index(drop=False))\n",
    "yield_data_pivot = yield_data_pivot.loc[yield_data_pivot[\"harvest_year\"].between(2004, 2023)].reset_index(drop=True)\n",
    "yield_data_pivot = yield_data_pivot.set_index([\"adm_id\", \"harvest_year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = []\n",
    "for row in yield_data_pivot.index:\n",
    "    temp = yield_data_pivot.loc[row, list(range(row[1]-5, row[1]))]\n",
    "    temp = pd.DataFrame(dict(zip([f\"yield_{i}\" for i in range(-5, 0)], temp.values), index=[0])).drop(columns=[\"index\"])\n",
    "    temp = temp.interpolate(axis=1, limit_direction=\"both\")\n",
    "    temp = temp.set_index(pd.MultiIndex.from_tuples([row])).reset_index().rename(columns={\"level_0\": \"adm_id\", \"level_1\": \"harvest_year\"})\n",
    "    li.append(temp)\n",
    "\n",
    "yield_past_years = pd.concat(li, axis=0)\n",
    "yield_past_years = yield_past_years.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adm_id</th>\n",
       "      <th>harvest_year</th>\n",
       "      <th>yield_-5</th>\n",
       "      <th>yield_-4</th>\n",
       "      <th>yield_-3</th>\n",
       "      <th>yield_-2</th>\n",
       "      <th>yield_-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US-08-001</td>\n",
       "      <td>2010</td>\n",
       "      <td>2.2882</td>\n",
       "      <td>2.2882</td>\n",
       "      <td>2.2882</td>\n",
       "      <td>1.91805</td>\n",
       "      <td>2.45645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US-08-001</td>\n",
       "      <td>2009</td>\n",
       "      <td>2.2882</td>\n",
       "      <td>2.2882</td>\n",
       "      <td>2.2882</td>\n",
       "      <td>2.28820</td>\n",
       "      <td>1.91805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      adm_id  harvest_year  yield_-5  yield_-4  yield_-3  yield_-2  yield_-1\n",
       "0  US-08-001          2010    2.2882    2.2882    2.2882   1.91805   2.45645\n",
       "1  US-08-001          2009    2.2882    2.2882    2.2882   2.28820   1.91805"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yield_past_years.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge with predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictores_with_yield = predictors.merge(yield_past_years, on=[\"adm_id\", \"harvest_year\"], how=\"inner\")\n",
    "predictores_16day_bins_with_yield = predictors_16day_bins.merge(yield_past_years, on=[\"adm_id\", \"harvest_year\"], how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictores_with_yield.to_csv(\"../data/preprocessed/{}/cy_bench_8daybins_{}_{}_v7.csv\".format(country, crop, country), index=False)\n",
    "predictores_16day_bins_with_yield.to_csv(\"../data/preprocessed/{}/cy_bench_16daybins_{}_{}_v7.csv\".format(country, crop, country), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global-yield-forecast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
