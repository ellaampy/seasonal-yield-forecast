{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from modules import preprocess\n",
    "\n",
    "\n",
    "static_features = [\"awc\", \"bulk_density\", \"drainage_class_1\", \"drainage_class_2\", \"drainage_class_3\", \"drainage_class_4\", \"drainage_class_5\", \"drainage_class_6\"]\n",
    "temporal_prefixes = [\"tavg\", \"prec\", \"tmin\", \"tmax\", \"ndvi\", \"fpar\", \"rad\", \"et0\", \"cwb\", \"ssm\", \"rsm\"]\n",
    "# Enable autoreload for Jupyter notebooks\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Define study crop and country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/shapefiles/US/tl_2023_us_county/tl_2023_us_county.shp wheat US (9, 233) (2, 8)\n"
     ]
    }
   ],
   "source": [
    "# USER INPUTS\n",
    "country = \"US\" # one of [\"US\", \"BR\"]\n",
    "crop = \"wheat\" # one of [\"maize\", \"wheat\"]\n",
    "\n",
    "shapefile_path, crop_season_in_days_of_year, crop_season_in_months, _ = preprocess.get_study_metadata(country, crop)\n",
    "\n",
    "print(shapefile_path, crop, country, crop_season_in_days_of_year, crop_season_in_months)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Read data\n",
    "\n",
    "From CY-Bench, we have five predictor datasets. \n",
    "\n",
    "| **ID** | **Name**        | **Time** | **Variables**                         | **Steps**                                    | **Notebook**   |\n",
    "|--------|-----------------|----------|---------------------------------------|----------------------------------------------|----------------|\n",
    "| 1      | FPAR            | bins     | fpar                                  | filter adm_ids, filter crop season           | _this notebook_ |            \n",
    "| 2      | METEO           | daily    | tmin, tmax, prec, rad, tavg, et0, cwb | filter adm_ids, filter crop season,<br>resample to 8-day bins  | _3_ecmwf_preprocessing.ipynb (tmin, tmax, tavg, prec_) <br>_this notebook_ (et0, rad, cwb) |       \n",
    "| 3      | NDVI            | bins     | ndvi                                  | filter adm_ids, filter crop season, pivotieren           | _this notebook_ |           \n",
    "| 4      | SOIL MOISTURE   | daily    | ssm, rsm                              | filter adm_ids, filter crop season, <br>resample to 8-day bins, pivotieren  | _this notebook_ |          \n",
    "| 5      | SOIL            | static   | awc, bulk_density, drainage_class     | filter adm_ids, pivotieren                                | _this notebook_ |         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CY-Bench data\n",
    "fpar = pd.read_csv(\"../data/CY-Bench/{}/{}/fpar_{}_{}.csv\".format(country, crop, crop, country)) \n",
    "meteo = pd.read_csv(\"../data/CY-Bench/{}/{}/meteo_{}_{}.csv\".format(country, crop, crop, country), usecols=['crop_name','adm_id','date','rad','et0','cwb', 'tavg', 'tmin', 'tmax', 'prec'])\n",
    "ndvi = pd.read_csv(\"../data/CY-Bench/{}/{}/ndvi_{}_{}.csv\".format(country, crop, crop, country))\n",
    "soil_moisture = pd.read_csv(\"../data/CY-Bench/{}/{}/soil_moisture_{}_{}.csv\".format(country, crop, crop, country))\n",
    "soil = pd.read_csv(\"../data/CY-Bench/{}/{}/soil_{}_{}.csv\".format(country, crop, crop, country))\n",
    "yield_data = pd.read_csv(\"../data/CY-Bench/{}/{}/yield_{}_{}.csv\".format(country, crop, crop, country))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cy_bench_data = [fpar, soil_moisture, ndvi, soil, meteo]\n",
    "relevant_adm_ids = yield_data[\"adm_id\"].unique()\n",
    "cy_bench_data = preprocess.filter_predictors_by_adm_ids(cy_bench_data, relevant_adm_ids)\n",
    "fpar, soil_moisture, ndvi, soil, meteo = cy_bench_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_season_in_days_of_year = tuple([1, 365])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ToDos\n",
    "\n",
    "- don't filter crop season\n",
    "- add fpar interpolation\n",
    "- provide two dataframes (8-day and 16-day bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agg\n",
      "assign\n",
      "agg\n",
      "assign\n",
      "agg\n",
      "assign\n",
      "agg\n",
      "assign\n"
     ]
    }
   ],
   "source": [
    "temporal_cy_bench_data = [fpar, soil_moisture, ndvi, meteo]\n",
    "temporal_cy_bench_data = preprocess.preprocess_temporal_data(temporal_cy_bench_data, crop_season_in_days_of_year)\n",
    "\n",
    "fpar, soil_moisture, ndvi, meteo = temporal_cy_bench_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_fpar_timesteps(df, reference_quantity):\n",
    "    \"\"\"\n",
    "    interpolate fpar values for all timesteps of a reference quantity.\n",
    "    \n",
    "    Params:\n",
    "        df: pd.DataFrame, dataframe containing the fpar columns\n",
    "        reference_quantity: str, reference quantity with complete timesteps\n",
    "        \n",
    "    Returns:\n",
    "        df: pd.DataFrame, dataframe with interpolated fpar values\n",
    "    \n",
    "    \"\"\"\n",
    "    min_time_step = min([int(c.split(\"_\")[1]) for c in [l for l in df.columns if reference_quantity in l]])\n",
    "    max_time_step = max([int(c.split(\"_\")[1]) for c in [l for l in df.columns if reference_quantity in l]])\n",
    "    fpar_columns = [c for c in df.columns if \"fpar\" in c]\n",
    "    fpar_columns_all_timesteps = [\"fpar_{}\".format(n) for n in list(range(min_time_step, max_time_step + 1))]\n",
    "    new_fpar_columns = list(set(fpar_columns_all_timesteps).difference(set(fpar_columns)))\n",
    "    df[new_fpar_columns] = np.nan\n",
    "    df[fpar_columns_all_timesteps] = df[fpar_columns_all_timesteps].interpolate(method='linear', axis=1, limit_direction='both')\n",
    "    df = df.reindex(sorted(df.columns), axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def temporal_aggregation(df, feature_prefix_list, window_size):\n",
    "    \"\"\"\n",
    "    Aggregate steps of temporal features and return the resulting dataframe.\n",
    "    \n",
    "    Params:\n",
    "        df: pd.DataFrame, dataframe containing the features and time steps as column names\n",
    "        feature_prefix_list: list, list of prefixes of temporal features that should be aggregated\n",
    "        window_size: int, number of steps to aggregate by \n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.set_index(static_features + [\"adm_id\", \"harvest_year\"], append=False)\n",
    "    li = []\n",
    "    for feature in feature_prefix_list:\n",
    "        res = df[get_temporal_feature_subset(df, [feature])].rolling(window=window_size, min_periods=1, axis=1).mean()\n",
    "        res = res.iloc[:, 1::2]\n",
    "        li.append(res)\n",
    "    \n",
    "    df = pd.concat(li, axis=1).reset_index()\n",
    "    return df\n",
    "\n",
    "def get_temporal_feature_subset(df, feature_prefix_list):\n",
    "    \"\"\"\n",
    "    Filter temporal features by prefix and return the resulting list of features names.\n",
    "    \n",
    "    Params:\n",
    "        df: pd.DataFrame, dataframe containing the features as column names\n",
    "        feature_prefix_list: list, list of prefixes to filter by\n",
    "    \n",
    "    Returns:\n",
    "        filtered_temporal_features: list, list of filtered temporal feature names\n",
    "    \"\"\"\n",
    "    all_columns = df.columns\n",
    "    filtered_temporal_features = [f for f in all_columns if any([f.startswith(prefix) for prefix in feature_prefix_list])]\n",
    "    return filtered_temporal_features\n",
    "\n",
    "def order_temporal_features(df, temporal_prefixes):\n",
    "    candidate_columns = [c for c in df.columns if c.split(\"_\")[0] in temporal_prefixes]\n",
    "    formated_candidate_columns = format_column_names(candidate_columns)\n",
    "    df = df.rename(columns=dict(zip(candidate_columns, formated_candidate_columns)))\n",
    "    df = df.reindex(sorted(df.columns), axis=1)\n",
    "    df = df.set_index([\"harvest_year\"], append=True).reset_index(level=[1])\n",
    "    return df\n",
    "\n",
    "def format_column_names(column_names):\n",
    "    formatted_columns = []\n",
    "    for name in column_names:\n",
    "        prefix, number = name.split('_')\n",
    "        formatted_name = f\"{prefix}_{int(number):02d}\"\n",
    "        formatted_columns.append(formatted_name)\n",
    "    return formatted_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge\n",
    "predictors = (soil_moisture\n",
    "              .merge(ndvi\n",
    "                     .merge(meteo\n",
    "                            .merge(fpar, on=[\"adm_id\", \"harvest_year\"], how=\"inner\"), \n",
    "                            on=[\"adm_id\", \"harvest_year\"], how=\"inner\"), \n",
    "                     on=[\"adm_id\", \"harvest_year\"], how=\"inner\")\n",
    "              .merge(soil.drop(\"crop_name\", axis=1), on=\"adm_id\", how=\"left\"))\n",
    "\n",
    "# one-hot encode drainage_class and drop\n",
    "predictors = (predictors\n",
    "              .join(pd.get_dummies(predictors[\"drainage_class\"].astype('Int64'), dtype=int, prefix=\"drainage_class\"))\n",
    "              .drop(\"drainage_class\", axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = interpolate_fpar_timesteps(predictors, \"tavg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = order_temporal_features(predictors, temporal_prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_16day_bins = temporal_aggregation(predictors, temporal_prefixes, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>awc</th>\n",
       "      <th>bulk_density</th>\n",
       "      <th>drainage_class_1</th>\n",
       "      <th>drainage_class_2</th>\n",
       "      <th>drainage_class_3</th>\n",
       "      <th>drainage_class_4</th>\n",
       "      <th>drainage_class_5</th>\n",
       "      <th>drainage_class_6</th>\n",
       "      <th>adm_id</th>\n",
       "      <th>harvest_year</th>\n",
       "      <th>...</th>\n",
       "      <th>rsm_27</th>\n",
       "      <th>rsm_29</th>\n",
       "      <th>rsm_31</th>\n",
       "      <th>rsm_33</th>\n",
       "      <th>rsm_35</th>\n",
       "      <th>rsm_37</th>\n",
       "      <th>rsm_39</th>\n",
       "      <th>rsm_41</th>\n",
       "      <th>rsm_43</th>\n",
       "      <th>rsm_45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.436359</td>\n",
       "      <td>1.342325</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>US-01-001</td>\n",
       "      <td>2004</td>\n",
       "      <td>...</td>\n",
       "      <td>382.726433</td>\n",
       "      <td>378.93025</td>\n",
       "      <td>390.162439</td>\n",
       "      <td>392.782368</td>\n",
       "      <td>371.961714</td>\n",
       "      <td>387.878651</td>\n",
       "      <td>413.388439</td>\n",
       "      <td>431.495993</td>\n",
       "      <td>446.502943</td>\n",
       "      <td>444.545958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 263 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         awc  bulk_density  drainage_class_1  drainage_class_2  \\\n",
       "0  11.436359      1.342325                 0                 0   \n",
       "\n",
       "   drainage_class_3  drainage_class_4  drainage_class_5  drainage_class_6  \\\n",
       "0                 0                 1                 0                 0   \n",
       "\n",
       "      adm_id  harvest_year  ...      rsm_27     rsm_29      rsm_31  \\\n",
       "0  US-01-001          2004  ...  382.726433  378.93025  390.162439   \n",
       "\n",
       "       rsm_33      rsm_35      rsm_37      rsm_39      rsm_41      rsm_43  \\\n",
       "0  392.782368  371.961714  387.878651  413.388439  431.495993  446.502943   \n",
       "\n",
       "       rsm_45  \n",
       "0  444.545958  \n",
       "\n",
       "[1 rows x 263 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors_16day_bins.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors.to_csv(\"../data/preprocessed/{}/cy_bench_8daybins_{}_{}.csv\".format(country, crop, country), index=False)\n",
    "predictors_16day_bins.to_csv(\"../data/preprocessed/{}/cy_bench_16daybins_{}_{}.csv\".format(country, crop, country), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global-yield-forecast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
